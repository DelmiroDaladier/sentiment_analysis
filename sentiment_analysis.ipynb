{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "work_dir = listdir('aclImdb/train/pos/')\n",
    "positive_reviews = []\n",
    "\n",
    "for review in work_dir:\n",
    "    with open(f'aclImdb/train/pos/{review}','r') as f:\n",
    "        positive_reviews.append(f.read())\n",
    "\n",
    "work_dir = listdir('aclImdb/train/neg/')\n",
    "negative_reviews = []\n",
    "for review in work_dir:\n",
    "    with open(f'aclImdb/train/neg/{review}','r') as f:\n",
    "        negative_reviews.append(f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_labels = [0 for review in negative_reviews] \n",
    "positive_labels = [1 for review in positive_reviews] \n",
    "reviews = positive_reviews + negative_reviews\n",
    "labels = positive_labels + negative_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "vocabulary_size = 500\n",
    "t = Tokenizer(num_words= vocabulary_size)\n",
    "\n",
    "t.fit_on_texts(reviews) \n",
    "encoded_reviews = t.texts_to_sequences(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                                    encoded_reviews, labels,\n",
    "                                                    test_size=0.3, random_state=1\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Processing reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 500, 32)           64000     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 117,301\n",
      "Trainable params: 117,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "embedding_size=32\n",
    "model=Sequential()\n",
    "model.add(Embedding(2000, embedding_size, input_length=max_words))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14000 samples, validate on 3500 samples\n",
      "Epoch 1/10\n",
      "14000/14000 [==============================] - 54s 4ms/step - loss: 0.4340 - accuracy: 0.8056 - val_loss: 0.4198 - val_accuracy: 0.8120\n",
      "Epoch 2/10\n",
      "14000/14000 [==============================] - 56s 4ms/step - loss: 0.3931 - accuracy: 0.8291 - val_loss: 0.3983 - val_accuracy: 0.8200\n",
      "Epoch 3/10\n",
      "14000/14000 [==============================] - 56s 4ms/step - loss: 0.3733 - accuracy: 0.8398 - val_loss: 0.3917 - val_accuracy: 0.8223\n",
      "Epoch 4/10\n",
      "14000/14000 [==============================] - 57s 4ms/step - loss: 0.3701 - accuracy: 0.8437 - val_loss: 0.3988 - val_accuracy: 0.8203\n",
      "Epoch 5/10\n",
      "14000/14000 [==============================] - 57s 4ms/step - loss: 0.3734 - accuracy: 0.8421 - val_loss: 0.3996 - val_accuracy: 0.8251\n",
      "Epoch 6/10\n",
      "14000/14000 [==============================] - 58s 4ms/step - loss: 0.3538 - accuracy: 0.8492 - val_loss: 0.3852 - val_accuracy: 0.8351\n",
      "Epoch 7/10\n",
      "14000/14000 [==============================] - 58s 4ms/step - loss: 0.3558 - accuracy: 0.8464 - val_loss: 0.3803 - val_accuracy: 0.8329\n",
      "Epoch 8/10\n",
      "14000/14000 [==============================] - 59s 4ms/step - loss: 0.3494 - accuracy: 0.8534 - val_loss: 0.3794 - val_accuracy: 0.8360\n",
      "Epoch 9/10\n",
      "14000/14000 [==============================] - 58s 4ms/step - loss: 0.3579 - accuracy: 0.8465 - val_loss: 0.3971 - val_accuracy: 0.8211\n",
      "Epoch 10/10\n",
      "14000/14000 [==============================] - 58s 4ms/step - loss: 0.3552 - accuracy: 0.8506 - val_loss: 0.3822 - val_accuracy: 0.8329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7eff2c2f1f90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.20,batch_size=500, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8345333337783813\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02807844],\n",
       "       [0.9667443 ],\n",
       "       [0.03876644],\n",
       "       ...,\n",
       "       [0.09576827],\n",
       "       [0.11786565],\n",
       "       [0.8553895 ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
